{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2cb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843396a",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773e8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('dataset_diabetes/X_array.npy',allow_pickle=True)\n",
    "readmission=np.load('dataset_diabetes/Y.npy',allow_pickle=True)\n",
    "encounter_id=np.load('dataset_diabetes/encounter_id.npy',allow_pickle=True)\n",
    "patient_nbr=np.load('dataset_diabetes/patient_nbr.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b12848a",
   "metadata": {},
   "source": [
    "## One Hot encoding and Convert readmission to binary Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b22b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = np.where(readmission == 'NO', 0, readmission)\n",
    "my_list2 = np.where(my_list == '>30', 0, my_list)\n",
    "Y0 = np.where(my_list2 == '<30', 1, my_list2)\n",
    "Y=list(Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5956c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101766, 468)\n"
     ]
    }
   ],
   "source": [
    "#convert to binary\n",
    "binarydat=OneHotEncoder().fit_transform(X)\n",
    "print(binarydat.shape)\n",
    "#split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(binarydat, Y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3227343",
   "metadata": {},
   "source": [
    "# Decision tree parameter testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "568be4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for max_features=100 and max_depth=7 is: \n",
      "0.8905398564750022\n",
      "Score for max_features=100 and max_depth=14 is: \n",
      "0.8860435339308579\n",
      "Score for max_features=100 and max_depth=21 is: \n",
      "0.8752047166721257\n",
      "Score for max_features=150 and max_depth=7 is: \n",
      "0.8908971801208945\n",
      "Score for max_features=150 and max_depth=14 is: \n",
      "0.8871750588095167\n",
      "Score for max_features=150 and max_depth=21 is: \n",
      "0.8790161688949766\n",
      "Score for max_features=200 and max_depth=7 is: \n",
      "0.8907780722389305\n",
      "Score for max_features=200 and max_depth=14 is: \n",
      "0.8850013399636721\n",
      "Score for max_features=200 and max_depth=21 is: \n",
      "0.8735669832951195\n",
      "Best score: 0.8908971801208945\n",
      "Best max_depth: 7\n",
      "Best score max_features: 150\n"
     ]
    }
   ],
   "source": [
    "#do some classifyin'\n",
    "testnums2=[7,14,21]\n",
    "testnums1=[100,150,200]\n",
    "scoretemp=0\n",
    "for n in testnums1:\n",
    "    for m in testnums2:\n",
    "        clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=m,max_features=n,random_state=1)\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        print('Score for max_features='+str(n)+' and max_depth='+str(m)+' is: ')\n",
    "        print(clf.score(X_test, y_test))\n",
    "        scoretemp1=clf.score(X_test, y_test)\n",
    "        if scoretemp1>scoretemp:\n",
    "            scoretemp=scoretemp1\n",
    "            best_max_depth=m\n",
    "            best_max_features=n\n",
    "print('Best score: '+str(scoretemp))\n",
    "print('Best max_depth: '+str(best_max_depth))\n",
    "print('Best score max_features: '+str(best_max_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96cd959",
   "metadata": {},
   "source": [
    "# Train decision tree on all data using 'best' parameters tested above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac8796f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=7,max_features=150,random_state=1)\n",
    "clf = clf.fit(binarydat, Y)\n",
    "len(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae74c826",
   "metadata": {},
   "source": [
    "## View unique feature importances (most will be zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e6e92cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00074226, 0.00078891, 0.00079485, 0.00135004,\n",
       "       0.00138169, 0.00143278, 0.00147069, 0.00168874, 0.00180788,\n",
       "       0.00183164, 0.00186571, 0.00189319, 0.00211249, 0.00211617,\n",
       "       0.00215589, 0.00215697, 0.00222717, 0.00242781, 0.00252509,\n",
       "       0.00262002, 0.00264797, 0.00290677, 0.00296329, 0.00340416,\n",
       "       0.00352472, 0.00377954, 0.00422767, 0.00433208, 0.00512859,\n",
       "       0.00533508, 0.00709424, 0.00736306, 0.00764933, 0.00825355,\n",
       "       0.00925191, 0.0107805 , 0.010832  , 0.02125533, 0.08330762,\n",
       "       0.10384427, 0.10493506, 0.10601352, 0.10943057, 0.33634921])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155d31a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e378d00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00422767,\n",
       "       0.        , 0.        , 0.00078891, 0.00764933, 0.        ,\n",
       "       0.        , 0.10384427, 0.        , 0.0107805 , 0.        ,\n",
       "       0.        , 0.        , 0.00138169, 0.        , 0.        ,\n",
       "       0.        , 0.10493506, 0.        , 0.        , 0.00211617,\n",
       "       0.00340416, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.10943057, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.010832  , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00433208,\n",
       "       0.00079485, 0.        , 0.00296329, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00290677, 0.        , 0.        ,\n",
       "       0.        , 0.00143278, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00222717,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00135004, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00183164, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00211249,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00180788,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00168874, 0.        , 0.        ,\n",
       "       0.00074226, 0.        , 0.00215589, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00252509, 0.        ,\n",
       "       0.        , 0.00189319, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.10601352, 0.02125533, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.33634921, 0.08330762, 0.        , 0.        , 0.00262002,\n",
       "       0.00512859, 0.00533508, 0.        , 0.        , 0.00352472,\n",
       "       0.        , 0.00709424, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00825355,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00242781,\n",
       "       0.        , 0.        , 0.        , 0.00186571, 0.        ,\n",
       "       0.        , 0.00147069, 0.        , 0.        , 0.        ,\n",
       "       0.00264797, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00215697, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00736306, 0.00377954,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00925191, 0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
