{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0bc9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cfa4c4",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fe9c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.load('dataset_diabetes/X_array.npy',allow_pickle=True)\n",
    "readmission=np.load('dataset_diabetes/Y.npy',allow_pickle=True)\n",
    "encounter_id=np.load('dataset_diabetes/encounter_id.npy',allow_pickle=True)\n",
    "patient_nbr=np.load('dataset_diabetes/patient_nbr.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd755ec2",
   "metadata": {},
   "source": [
    "## One Hot encoding and Convert readmission to binary Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b66f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = np.where(readmission == 'NO', 0, readmission)\n",
    "my_list2 = np.where(my_list == '>30', 0, my_list)\n",
    "Y0 = np.where(my_list2 == '<30', 1, my_list2)\n",
    "Y=list(Y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b267a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101766, 468)\n"
     ]
    }
   ],
   "source": [
    "#convert to binary\n",
    "binarydat=OneHotEncoder().fit_transform(X)\n",
    "print(binarydat.shape)\n",
    "binarydat_unpacked=csr_matrix(binarydat).toarray()\n",
    "#split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(binarydat_unpacked, Y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f7e60b",
   "metadata": {},
   "source": [
    "# Decision tree parameter testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e6b018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for max_features=100 and max_depth=7 is: \n",
      "0.8905398564750022\n",
      "Score for max_features=100 and max_depth=14 is: \n",
      "0.8860435339308579\n",
      "Score for max_features=100 and max_depth=21 is: \n",
      "0.8752047166721257\n",
      "Score for max_features=150 and max_depth=7 is: \n",
      "0.8908971801208945\n",
      "Score for max_features=150 and max_depth=14 is: \n",
      "0.8871750588095167\n",
      "Score for max_features=150 and max_depth=21 is: \n",
      "0.8790161688949766\n",
      "Score for max_features=200 and max_depth=7 is: \n",
      "0.8907780722389305\n",
      "Score for max_features=200 and max_depth=14 is: \n",
      "0.8850013399636721\n",
      "Score for max_features=200 and max_depth=21 is: \n",
      "0.8735669832951195\n",
      "Best score: 0.8908971801208945\n",
      "Best max_depth: 7\n",
      "Best score max_features: 150\n"
     ]
    }
   ],
   "source": [
    "#do some classifyin'\n",
    "testnums2=[7,14,21]\n",
    "testnums1=[100,150,200]\n",
    "scoretemp=0\n",
    "for n in testnums1:\n",
    "    for m in testnums2:\n",
    "        clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=m,max_features=n,random_state=1)\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        print('Score for max_features='+str(n)+' and max_depth='+str(m)+' is: ')\n",
    "        print(clf.score(X_test, y_test))\n",
    "        scoretemp1=clf.score(X_test, y_test)\n",
    "        if scoretemp1>scoretemp:\n",
    "            scoretemp=scoretemp1\n",
    "            best_max_depth=m\n",
    "            best_max_features=n\n",
    "print('Best score: '+str(scoretemp))\n",
    "print('Best max_depth: '+str(best_max_depth))\n",
    "print('Best score max_features: '+str(best_max_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32542c0",
   "metadata": {},
   "source": [
    "# Train decision tree on all data using 'best' parameters tested above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30949252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy',max_depth=7,max_features=150,random_state=1)\n",
    "clf = clf.fit(binarydat_unpacked, Y)\n",
    "len(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543cacb6",
   "metadata": {},
   "source": [
    "## View unique feature importances (most will be zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f9145f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00074226, 0.00078891, 0.00079485, 0.00135004,\n",
       "       0.00138169, 0.00143278, 0.00147069, 0.00168874, 0.00180788,\n",
       "       0.00183164, 0.00186571, 0.00189319, 0.00211249, 0.00211617,\n",
       "       0.00215589, 0.00215697, 0.00222717, 0.00242781, 0.00252509,\n",
       "       0.00262002, 0.00264797, 0.00290677, 0.00296329, 0.00340416,\n",
       "       0.00352472, 0.00377954, 0.00422767, 0.00433208, 0.00512859,\n",
       "       0.00533508, 0.00709424, 0.00736306, 0.00764933, 0.00825355,\n",
       "       0.00925191, 0.0107805 , 0.010832  , 0.02125533, 0.08330762,\n",
       "       0.10384427, 0.10493506, 0.10601352, 0.10943057, 0.33634921])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158a38e",
   "metadata": {},
   "source": [
    "## Delete features whose importance is ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca36632",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance=clf.feature_importances_\n",
    "importance_na = np.where(importance == 0, 'NA', importance)\n",
    "#to further reduce features you can do a line similar to the above but instead of saying... \n",
    "# importance ==0\n",
    "# you could say importance <0.01 or whatever threshold you want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c9b3806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8884008411453728"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking something...\n",
    "Y.count(0)/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49f6f26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kat\\AppData\\Local\\Temp/ipykernel_11384/2679394929.py:3: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n",
      "  x2 = np.delete(binarydat_unpacked, index,axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(101766, 44)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NA_added=np.vstack([binarydat_unpacked,importance_na])\n",
    "index = np.argwhere(NA_added=='NA')\n",
    "x2 = np.delete(binarydat_unpacked, index,axis=1)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f7b1e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 468)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarydat_unpacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bca84101",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset_diabetes/tree_selected_44X.npy',x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
