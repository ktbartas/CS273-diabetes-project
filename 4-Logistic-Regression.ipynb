{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8804eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "756f03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data (X - selected features)\n",
    "X1=np.load('dataset_diabetes/tree_selected_25_X.npy',allow_pickle=True) #decision tree top 25\n",
    "X2=np.load('dataset_diabetes/SVD_selected_25_X.npy',allow_pickle=True) # SVD top 25\n",
    "\n",
    "#import and format Y (labels for our classifier - readmitted=1 or not (at least not soon)=0)\n",
    "readmission=np.load('dataset_diabetes/Y.npy',allow_pickle=True)\n",
    "my_list = np.where(readmission == 'NO', 0, readmission)\n",
    "my_list2 = np.where(my_list == '>30', 0, my_list)\n",
    "Y0 = np.where(my_list2 == '<30', 1, my_list2)\n",
    "Y=list(Y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615ae21",
   "metadata": {},
   "source": [
    "# Check to make sure data is size I expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e2c403b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 25)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape # features chosen by decision tree (binary, meaningful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e0833e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape # features chosen by SVD - not binary, not rly meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf54d0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101766"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6676a9",
   "metadata": {},
   "source": [
    "# Split into train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85dc9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabel X arrays\n",
    "X_DT = X1\n",
    "X_SVD = X2\n",
    "\n",
    "# Split data\n",
    "XDT_train, XDT_test, YDT_train, YDT_test = train_test_split(X_DT, Y, test_size=0.33, random_state=1)\n",
    "XSVD_train, XSVD_test, YSVD_train, YSVD_test = train_test_split(X_SVD, Y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97adb144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68183, 25)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XDT_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "560debb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68183, 25)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XSVD_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f262d62",
   "metadata": {},
   "source": [
    "# Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a7cb6",
   "metadata": {},
   "source": [
    "## Default Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a9002cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60381   102]\n",
      " [ 7589   111]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29854    72]\n",
      " [ 3613    44]]\n",
      "The percentage of correct training assignments is:  0.8870686241438481\n",
      "The percentage of correct test assignments is:  0.8911056189143317\n"
     ]
    }
   ],
   "source": [
    "### Default Log regression\n",
    "DT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none').fit(XDT_train, YDT_train)\n",
    "SVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none').fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = DT_logit.predict(XDT_train)\n",
    "YhatDT_test = DT_logit.predict(XDT_test)\n",
    "YhatSVD_train = SVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = SVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9dbb4",
   "metadata": {},
   "source": [
    "## Class weight: balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a460c7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[36898 23585]\n",
      " [ 3290  4410]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[18125 11801]\n",
      " [ 1552  2105]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[42500 17983]\n",
      " [ 3670  4030]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[20864  9062]\n",
      " [ 1707  1950]]\n",
      "The percentage of correct training assignments is:  0.6058401654371324\n",
      "The percentage of correct test assignments is:  0.60238811303338\n"
     ]
    }
   ],
   "source": [
    "balancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight='balanced').fit(XDT_train, YDT_train)\n",
    "balancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight='balanced').fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = balancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = balancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = balancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = balancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d2dc3",
   "metadata": {},
   "source": [
    "## Custom class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23bbdcd",
   "metadata": {},
   "source": [
    "Here, we test a few values to see how the class weights affect the accuracy of our model. We use this information to pick a range to loop through below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a336e6e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[30708 29775]\n",
      " [ 2443  5257]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[14993 14933]\n",
      " [ 1139  2518]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[36171 24312]\n",
      " [ 2807  4893]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[17607 12319]\n",
      " [ 1295  2362]]\n",
      "The percentage of correct training assignments is:  0.5274775237229221\n",
      "The percentage of correct test assignments is:  0.5214245302682905\n"
     ]
    }
   ],
   "source": [
    "# {0:.1, 1:.9} Quite close to \"balanced\" since this is about the ratio seen in data\n",
    "custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight={0:.1, 1:.9}).fit(XDT_train, YDT_train)\n",
    "custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight={0:.1, 1:.9}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "638137c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7695     5]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3653     4]]\n",
      "The percentage of correct training assignments is:  0.8870686241438481\n",
      "The percentage of correct test assignments is:  0.8911056189143317\n"
     ]
    }
   ],
   "source": [
    "# {0:.9, 1:.1}\n",
    "custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight={0:.9, 1:.1}).fit(XDT_train, YDT_train)\n",
    "custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight={0:.9, 1:.1}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b93f50d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60381   102]\n",
      " [ 7590   110]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29855    71]\n",
      " [ 3613    44]]\n",
      "The percentage of correct training assignments is:  0.8870686241438481\n",
      "The percentage of correct test assignments is:  0.8911056189143317\n"
     ]
    }
   ],
   "source": [
    "# {0:.5, 1:.5}\n",
    "custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight={0:.5, 1:.5}).fit(XDT_train, YDT_train)\n",
    "custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight={0:.5, 1:.5}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69eca7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[25980 34503]\n",
      " [ 1884  5816]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[12628 17298]\n",
      " [  871  2786]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[30108 30375]\n",
      " [ 2144  5556]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[14730 15196]\n",
      " [  972  2685]]\n",
      "The percentage of correct training assignments is:  0.4663332502236628\n",
      "The percentage of correct test assignments is:  0.45898222314861686\n"
     ]
    }
   ],
   "source": [
    "# {0:1, 1:10}\n",
    "custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight={0:1, 1:10}).fit(XDT_train, YDT_train)\n",
    "custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, penalty='none',class_weight={0:1, 1:10}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e656d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop thru dictionaries\n",
    "\n",
    "zeroweights = np.linspace(0,5,11)\n",
    "oneweights = np.linspace(0,10,21)\n",
    "\n",
    "SVD_TrainAcc = [];\n",
    "SVD_TestAcc = [];\n",
    "DT_TrainAcc = [];\n",
    "DT_TestAcc = [];\n",
    "\n",
    "for zero in enumerate(zeroweights):\n",
    "    for one in enumerate(oneweights):\n",
    "        custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:zero[1], 1:one[1]}).fit(XDT_train, YDT_train)\n",
    "        custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:zero[1], 1:one[1]}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "        # Use model to make predictions\n",
    "        YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "        YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "        YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "        YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "        # Confusion matricies\n",
    "        CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "        CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "        CM_DT_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "        CM_DT_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "        # Scores\n",
    "        SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "        SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "        DT_Train_Correct = sum(np.diag(CM_DT_Train))\n",
    "        DT_Test_Correct = sum(np.diag(CM_DT_Test))\n",
    "        \n",
    "        # Save scores\n",
    "        SVD_TrainAcc.append(SVD_Train_Correct);\n",
    "        SVD_TestAcc.append(SVD_Test_Correct);\n",
    "        DT_TrainAcc.append(DT_Train_Correct);\n",
    "        DT_TestAcc.append(DT_Test_Correct);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "757c6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSVDTrainCount = max(SVD_TrainAcc)\n",
    "bestSVDTrainScore= maxSVDTrainCount/len(XSVD_train)\n",
    "bestindicies=np.where(SVD_TrainAcc==maxSVDTrainCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "336e7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSVDTestCount = max(SVD_TestAcc)\n",
    "bestSVDTestScore= maxSVDTestCount/len(XSVD_test)\n",
    "bestindicies = np.where(SVD_TestAcc==maxSVDTestCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c872fe30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 23,  46,  69,  92, 115, 138, 161, 184, 207, 230]),)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestindicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5760c14e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal weights are\n",
      "[0.5, 1.0] \n",
      "\n",
      "[1.0, 2.0] \n",
      "\n",
      "[1.5, 3.0] \n",
      "\n",
      "[2.0, 4.0] \n",
      "\n",
      "[2.5, 5.0] \n",
      "\n",
      "[3.0, 6.0] \n",
      "\n",
      "[3.5, 7.0] \n",
      "\n",
      "[4.0, 8.0] \n",
      "\n",
      "[4.5, 9.0] \n",
      "\n",
      "[5.0, 10.0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = [];\n",
    "\n",
    "for zero in enumerate(zeroweights):\n",
    "    for one in enumerate(oneweights):\n",
    "        weights.append([zero[1],one[1]])\n",
    "        \n",
    "bestindicies= np.reshape(bestindicies, [10,1])\n",
    "print('The optimal weights are')\n",
    "for i in range(len(bestindicies)):\n",
    "    print(weights[int(bestindicies[i])],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de309a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal weights are\n",
      "[3.0, 1.0] \n",
      "\n",
      "[3.5, 1.0] \n",
      "\n",
      "[3.5, 1.5] \n",
      "\n",
      "[4.0, 1.0] \n",
      "\n",
      "[4.5, 1.0] \n",
      "\n",
      "[4.5, 1.5] \n",
      "\n",
      "[4.5, 2.0] \n",
      "\n",
      "[5.0, 1.0] \n",
      "\n",
      "[5.0, 1.5] \n",
      "\n",
      "[5.0, 2.0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxDTTestCount = max(DT_TestAcc)\n",
    "bestDTTestScore= maxDTTestCount/len(XDT_test)\n",
    "bestindicies = np.where(DT_TestAcc==maxDTTestCount)\n",
    "\n",
    "bestindicies= np.reshape(bestindicies, [10,1])\n",
    "print('The optimal weights are')\n",
    "for i in range(len(bestindicies)):\n",
    "    print(weights[int(bestindicies[i])],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bbcf71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of correct SVD training assignments is:  0.8869952920816039\n",
      "The percentage of correct SVD test assignments is:  0.8911353958848227\n",
      "The percentage of correct DT training assignments is:  0.8871419562060924\n",
      "The percentage of correct DT test assignments is:  0.8912247267962957\n"
     ]
    }
   ],
   "source": [
    "# DT Classweight = {0:4, 1:1}\n",
    "# SVD Classweight ={0:.5, 1:1}\n",
    "\n",
    "custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:4, 1:1}).fit(XDT_train, YDT_train)\n",
    "custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:.5, 1:1}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "CM_DT_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_DT_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "# Scores\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "DT_Train_Correct = sum(np.diag(CM_DT_Train))\n",
    "DT_Test_Correct = sum(np.diag(CM_DT_Test))\n",
    "\n",
    "# # Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct SVD training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct SVD test assignments is: ',SVD_Test_Correct/SVD_Test_Total)\n",
    "\n",
    "DT_Train_Correct = sum(np.diag(CM_DT_Train))\n",
    "DT_Train_Total = len(XDT_train)\n",
    "print('The percentage of correct DT training assignments is: ',DT_Train_Correct/DT_Train_Total)\n",
    "\n",
    "DT_Test_Correct = sum(np.diag(CM_DT_Test))\n",
    "DT_Test_Total = len(XDT_test)\n",
    "print('The percentage of correct DT test assignments is: ',DT_Test_Correct/DT_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b99c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60418    65]\n",
      " [ 7633    67]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29873    53]\n",
      " [ 3630    27]]\n"
     ]
    }
   ],
   "source": [
    "### Stochastic Gradient Descent- tried with combos of penalty/no penalty and classweight didn't change\n",
    "import sklearn.linear_model\n",
    "SGDDT_logit = sklearn.linear_model.SGDClassifier(loss='log',random_state=1, max_iter=10000,tol=1e-8,penalty='none', class_weight='balanced').fit(XDT_train, YDT_train)\n",
    "SGDSVD_logit = sklearn.linear_model.SGDClassifier(loss='log',random_state=1, max_iter=10000,tol=1e-8,penalty='none', class_weight='balanced').fit(XSVD_train, YSVD_train)\n",
    "\n",
    "SGDYhatDT_train = SGDDT_logit.predict(XDT_train)\n",
    "SGDYhatDT_test = SGDDT_logit.predict(XDT_test)\n",
    "\n",
    "SGDYhatSVD_train = SGDSVD_logit.predict(XSVD_train)\n",
    "SGDYhatSVD_test = SGDSVD_logit.predict(XSVD_test)\n",
    "\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba293ba2",
   "metadata": {},
   "source": [
    "# Test accuracy (Older/Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb3c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "YhatDT_train = DT_logit.predict(XDT_train)\n",
    "YhatDT_test = DT_logit.predict(XDT_test)\n",
    "\n",
    "YhatSVD_train = SVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = SVD_logit.predict(XSVD_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e5a6c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33583,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YhatSVD_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a278f",
   "metadata": {},
   "source": [
    "# Confusion Matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd3080a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60418    65]\n",
      " [ 7633    67]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29873    53]\n",
      " [ 3630    27]]\n"
     ]
    }
   ],
   "source": [
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0771abc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Training Data Set:\n",
      "Total Readmitted Patients: 7700\n",
      "Total Correctly Predicted: 0\n",
      "\n",
      "Tree Training Data Set:\n",
      "Total Readmitted Patients: 7700\n",
      "Total Correctly Predicted: 67\n"
     ]
    }
   ],
   "source": [
    "SVD_train_total = np.sum(CM_SVD_Train,axis=1)[1];\n",
    "SVD_train_correct = CM_SVD_Train[1][1];\n",
    "\n",
    "Tree_train_total = np.sum(CM_Tree_Train,axis=1)[1];\n",
    "Tree_train_correct = CM_Tree_Train[1][1];\n",
    "\n",
    "print('SVD Training Data Set:')\n",
    "print('Total Readmitted Patients: '+str(SVD_train_total))\n",
    "print('Total Correctly Predicted: '+str(SVD_train_correct)+'\\n')\n",
    "print('Tree Training Data Set:')\n",
    "print('Total Readmitted Patients: '+str(Tree_train_total))\n",
    "print('Total Correctly Predicted: '+str(Tree_train_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5814df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Test Data Set:\n",
      "Total Readmitted Patients: 3657\n",
      "Total Correctly Predicted: 0\n",
      "\n",
      "Tree Test Data Set:\n",
      "Total Readmitted Patients: 3657\n",
      "Total Correctly Predicted: 27\n"
     ]
    }
   ],
   "source": [
    "SVD_test_total = np.sum(CM_SVD_Test,axis=1)[1];\n",
    "SVD_test_correct = CM_SVD_Test[1][1];\n",
    "\n",
    "Tree_test_total = np.sum(CM_Tree_Test,axis=1)[1];\n",
    "Tree_test_correct = CM_Tree_Test[1][1];\n",
    "\n",
    "print('SVD Test Data Set:')\n",
    "print('Total Readmitted Patients: '+str(SVD_test_total))\n",
    "print('Total Correctly Predicted: '+str(SVD_test_correct)+'\\n')\n",
    "print('Tree Test Data Set:')\n",
    "print('Total Readmitted Patients: '+str(Tree_test_total))\n",
    "print('Total Correctly Predicted: '+str(Tree_test_correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cdf735",
   "metadata": {},
   "source": [
    "From what you say it seems class 0 is 19 times more frequent than class 1. So you should increase the class_weight of class 1 relative to class 0, say {0:.9, 1:.1}.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7c66620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of correct assignments is:  0.5275361893727175\n"
     ]
    }
   ],
   "source": [
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "\n",
    "print('The percentage of correct assignments is: ',SVD_Train_Correct/SVD_Train_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3887b560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68183"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(CM_SVD_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "686c12c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68183"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(XSVD_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889cfc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
