{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8804eab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "756f03c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data (X - selected features)\n",
    "X1=np.load('dataset_diabetes/tree_selected_25_X.npy',allow_pickle=True) #decision tree top 25\n",
    "X2=np.load('dataset_diabetes/SVD_selected_25_X.npy',allow_pickle=True) # SVD top 25\n",
    "\n",
    "#import and format Y (labels for our classifier - readmitted=1 or not (at least not soon)=0)\n",
    "readmission=np.load('dataset_diabetes/Y.npy',allow_pickle=True)\n",
    "my_list = np.where(readmission == 'NO', 0, readmission)\n",
    "my_list2 = np.where(my_list == '>30', 0, my_list)\n",
    "Y0 = np.where(my_list2 == '<30', 1, my_list2)\n",
    "Y=list(Y0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615ae21",
   "metadata": {},
   "source": [
    "# Check to make sure data is size I expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e2c403b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape # features chosen by decision tree (binary, meaningful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e0833e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape # features chosen by SVD - not binary, not rly meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf54d0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101766"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6676a9",
   "metadata": {},
   "source": [
    "# Split into train and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85dc9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relabel X arrays\n",
    "X_DT = X1\n",
    "X_SVD = X2\n",
    "\n",
    "# Split data\n",
    "XDT_train, XDT_test, YDT_train, YDT_test = train_test_split(X_DT, Y, test_size=0.33, random_state=1)\n",
    "XSVD_train, XSVD_test, YSVD_train, YSVD_test = train_test_split(X_SVD, Y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97adb144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68183, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XDT_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560debb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68183, 25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XSVD_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f262d62",
   "metadata": {},
   "source": [
    "# Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7a7cb6",
   "metadata": {},
   "source": [
    "## Default Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a9002cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60418    65]\n",
      " [ 7633    67]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29873    53]\n",
      " [ 3630    27]]\n"
     ]
    }
   ],
   "source": [
    "### Default Log regression\n",
    "DT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8).fit(XDT_train, YDT_train)\n",
    "SVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = DT_logit.predict(XDT_train)\n",
    "YhatDT_test = DT_logit.predict(XDT_test)\n",
    "YhatSVD_train = SVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = SVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bebd43",
   "metadata": {},
   "source": [
    "## No penalty (Log Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e39d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60381   102]\n",
      " [ 7589   111]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29854    72]\n",
      " [ 3613    44]]\n",
      "The percentage of correct training assignments is:  0.8870686241438481\n",
      "The percentage of correct test assignments is:  0.8911056189143317\n"
     ]
    }
   ],
   "source": [
    "nopenDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,penalty='none').fit(XDT_train, YDT_train)\n",
    "nopenSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,penalty='none').fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = nopenDT_logit.predict(XDT_train)\n",
    "YhatDT_test = nopenDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = nopenSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = nopenSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9dbb4",
   "metadata": {},
   "source": [
    "## Class weight: balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a460c7a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[36895 23588]\n",
      " [ 3290  4410]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[18121 11805]\n",
      " [ 1553  2104]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[42501 17982]\n",
      " [ 3670  4030]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[20865  9061]\n",
      " [ 1707  1950]]\n",
      "The percentage of correct training assignments is:  0.6057961661997858\n",
      "The percentage of correct test assignments is:  0.6022392281809249\n"
     ]
    }
   ],
   "source": [
    "balancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight='balanced').fit(XDT_train, YDT_train)\n",
    "balancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight='balanced').fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = balancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = balancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = balancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = balancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243d2dc3",
   "metadata": {},
   "source": [
    "## Custom class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a336e6e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[30711 29772]\n",
      " [ 2442  5258]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[14995 14931]\n",
      " [ 1138  2519]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[36158 24325]\n",
      " [ 2806  4894]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[17603 12323]\n",
      " [ 1295  2362]]\n",
      "The percentage of correct training assignments is:  0.5275361893727175\n",
      "The percentage of correct test assignments is:  0.5215138611797636\n"
     ]
    }
   ],
   "source": [
    "# {0:.1, 1:.9} Quite close to \"balanced\" since this is about the ratio seen in data\n",
    "custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:.1, 1:.9}).fit(XDT_train, YDT_train)\n",
    "custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:.1, 1:.9}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "638137c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n"
     ]
    }
   ],
   "source": [
    "# {0:.9, 1:.1}\n",
    "custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:.9, 1:.1}).fit(XDT_train, YDT_train)\n",
    "custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:.9, 1:.1}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b93f50d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60430    53]\n",
      " [ 7645    55]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29883    43]\n",
      " [ 3638    19]]\n",
      "The percentage of correct training assignments is:  0.8870686241438481\n",
      "The percentage of correct test assignments is:  0.8911056189143317\n"
     ]
    }
   ],
   "source": [
    "# {0:.5, 1:.5}\n",
    "custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:.5, 1:.5}).fit(XDT_train, YDT_train)\n",
    "custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:.5, 1:.5}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69eca7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[30709 29774]\n",
      " [ 2443  5257]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[14993 14933]\n",
      " [ 1139  2518]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[ 1103 59380]\n",
      " [    0  7700]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[  543 29383]\n",
      " [    0  3657]]\n",
      "The percentage of correct training assignments is:  0.527492190135371\n",
      "The percentage of correct test assignments is:  0.5214245302682905\n"
     ]
    }
   ],
   "source": [
    "# {0:1, 1:20}\n",
    "custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:.5, 1:9}).fit(XDT_train, YDT_train)\n",
    "custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:1, 1:9}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "239d35c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[36898 23585]\n",
      " [ 3290  4410]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[18125 11801]\n",
      " [ 1552  2105]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[42500 17983]\n",
      " [ 3670  4030]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[20864  9062]\n",
      " [ 1707  1950]]\n",
      "The percentage of correct training assignments is:  0.6058401654371324\n",
      "The percentage of correct test assignments is:  0.60238811303338\n"
     ]
    }
   ],
   "source": [
    "### Mixed Log regression\n",
    "noPbalDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, class_weight='balanced', penalty='none').fit(XDT_train, YDT_train)\n",
    "noPbalSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8, class_weight='balanced', penalty='none').fit(XSVD_train, YSVD_train)\n",
    "\n",
    "# Use model to make predictions\n",
    "YhatDT_train = noPbalDT_logit.predict(XDT_train)\n",
    "YhatDT_test = noPbalDT_logit.predict(XDT_test)\n",
    "YhatSVD_train = noPbalSVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = noPbalSVD_logit.predict(XSVD_test)\n",
    "\n",
    "# Confusion matricies\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n",
    "\n",
    "# Score\n",
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "SVD_Test_Total = len(XSVD_test)\n",
    "print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e656d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop thru dictionaries\n",
    "\n",
    "zeroweights = np.linspace(0,5,11)\n",
    "oneweights = np.linspace(0,5,11)\n",
    "\n",
    "SVD_TrainAcc = [];\n",
    "SVD_TestAcc = [];\n",
    "DT_TrainAcc = [];\n",
    "DT_TestAcc = [];\n",
    "\n",
    "for zero in enumerate(zeroweights):\n",
    "    for one in enumerate(oneweights):\n",
    "        custombalancedDT_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:zero[1], 1:one[1]}).fit(XDT_train, YDT_train)\n",
    "        custombalancedSVD_logit = LogisticRegression(random_state=1, max_iter=10000,tol=1e-8,class_weight={0:zero[1], 1:one[1]}).fit(XSVD_train, YSVD_train)\n",
    "\n",
    "        # Use model to make predictions\n",
    "        YhatDT_train = custombalancedDT_logit.predict(XDT_train)\n",
    "        YhatDT_test = custombalancedDT_logit.predict(XDT_test)\n",
    "        YhatSVD_train = custombalancedSVD_logit.predict(XSVD_train)\n",
    "        YhatSVD_test = custombalancedSVD_logit.predict(XSVD_test)\n",
    "\n",
    "        # Confusion matricies\n",
    "        CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "        CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "        CM_DT_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "        CM_DT_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "        # Scores\n",
    "        SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "        SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "        DT_Train_Correct = sum(np.diag(CM_DT_Train))\n",
    "        DT_Test_Correct = sum(np.diag(CM_DT_Test))\n",
    "        \n",
    "        # Save scores\n",
    "        SVD_TrainAcc.append(SVD_Train_Correct);\n",
    "        SVD_TestAcc.append(SVD_Test_Correct);\n",
    "        DT_TrainAcc.append(DT_Train_Correct);\n",
    "        DT_TestAcc.append(DT_Test_Correct);\n",
    "\n",
    "# # Score\n",
    "# SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "# SVD_Train_Total = len(XSVD_train)\n",
    "# print('The percentage of correct training assignments is: ',SVD_Train_Correct/SVD_Train_Total)\n",
    "\n",
    "# SVD_Test_Correct = sum(np.diag(CM_SVD_Test))\n",
    "# SVD_Test_Total = len(XSVD_test)\n",
    "# print('The percentage of correct test assignments is: ',SVD_Test_Correct/SVD_Test_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "757c6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,  11,  12,  22,  23,  24,  25,  33,  34,  35,  36,  37,  38,\n",
       "         44,  45,  46,  47,  48,  49,  50,  51,  55,  56,  57,  58,  59,\n",
       "         60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  71,  72,  73,\n",
       "         74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,\n",
       "         87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99,\n",
       "        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
       "        113, 114, 115, 116, 117, 118, 119, 120]),)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxSVDTrainCount = max(SVD_TrainAcc)\n",
    "bestSVDTrainScore= maxSVDTrainCount/len(XSVD_train)\n",
    "bestindicies=np.where(SVD_TrainAcc==maxSVDTrainCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "336e7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSVDTestCount = max(SVD_TestAcc)\n",
    "bestSVDTestScore= maxSVDTestCount/len(XSVD_test)\n",
    "bestindicies = np.where(SVD_TestAcc==maxSVDTestCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5760c14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal weights are\n",
      "[0.5, 1.0] \n",
      "\n",
      "[1.0, 2.0] \n",
      "\n",
      "[1.5, 3.0] \n",
      "\n",
      "[2.0, 4.0] \n",
      "\n",
      "[2.5, 5.0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bestindicies\n",
    "weights = [];\n",
    "\n",
    "for zero in enumerate(zeroweights):\n",
    "    for one in enumerate(oneweights):\n",
    "        weights.append([zero[1],one[1]])\n",
    "        \n",
    "bestindicies= np.reshape(bestindicies, [5,1])\n",
    "print('The optimal weights are')\n",
    "for i in range(len(bestindicies)):\n",
    "    print(weights[int(bestindicies[i])],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "de309a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal weights are\n",
      "[3.0, 1.0] \n",
      "\n",
      "[3.5, 1.0] \n",
      "\n",
      "[3.5, 1.5] \n",
      "\n",
      "[4.0, 1.0] \n",
      "\n",
      "[4.5, 1.0] \n",
      "\n",
      "[4.5, 1.5] \n",
      "\n",
      "[4.5, 2.0] \n",
      "\n",
      "[5.0, 1.0] \n",
      "\n",
      "[5.0, 1.5] \n",
      "\n",
      "[5.0, 2.0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "maxDTTestCount = max(DT_TestAcc)\n",
    "bestDTTestScore= maxDTTestCount/len(XDT_test)\n",
    "bestindicies = np.where(DT_TestAcc==maxDTTestCount)\n",
    "\n",
    "bestindicies= np.reshape(bestindicies, [10,1])\n",
    "print('The optimal weights are')\n",
    "for i in range(len(bestindicies)):\n",
    "    print(weights[int(bestindicies[i])],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b99c71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60418    65]\n",
      " [ 7633    67]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29873    53]\n",
      " [ 3630    27]]\n"
     ]
    }
   ],
   "source": [
    "### Stochastic Gradient Descent- tried with combos of penalty/no penalty and classweight didn't change\n",
    "import sklearn.linear_model\n",
    "SGDDT_logit = sklearn.linear_model.SGDClassifier(loss='log',random_state=1, max_iter=10000,tol=1e-8,penalty='none', class_weight='balanced').fit(XDT_train, YDT_train)\n",
    "SGDSVD_logit = sklearn.linear_model.SGDClassifier(loss='log',random_state=1, max_iter=10000,tol=1e-8,penalty='none', class_weight='balanced').fit(XSVD_train, YSVD_train)\n",
    "\n",
    "SGDYhatDT_train = SGDDT_logit.predict(XDT_train)\n",
    "SGDYhatDT_test = SGDDT_logit.predict(XDT_test)\n",
    "\n",
    "SGDYhatSVD_train = SGDSVD_logit.predict(XSVD_train)\n",
    "SGDYhatSVD_test = SGDSVD_logit.predict(XSVD_test)\n",
    "\n",
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba293ba2",
   "metadata": {},
   "source": [
    "# Test accuracy (Older/Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb3c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "YhatDT_train = DT_logit.predict(XDT_train)\n",
    "YhatDT_test = DT_logit.predict(XDT_test)\n",
    "\n",
    "YhatSVD_train = SVD_logit.predict(XSVD_train)\n",
    "YhatSVD_test = SVD_logit.predict(XSVD_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e5a6c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33583,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YhatSVD_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742a278f",
   "metadata": {},
   "source": [
    "# Confusion Matricies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd3080a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Train Conf. Matrix: \n",
      "[[60483     0]\n",
      " [ 7700     0]]\n",
      "\n",
      "Tree Train Conf. Matrix: \n",
      "[[60418    65]\n",
      " [ 7633    67]]\n",
      "\n",
      "SVD Test Conf. Matrix: \n",
      "[[29926     0]\n",
      " [ 3657     0]]\n",
      "\n",
      "Tree Test Conf. Matrix: \n",
      "[[29873    53]\n",
      " [ 3630    27]]\n"
     ]
    }
   ],
   "source": [
    "CM_SVD_Train = confusion_matrix(YSVD_train,YhatSVD_train);\n",
    "CM_Tree_Train = confusion_matrix(YDT_train,YhatDT_train);\n",
    "\n",
    "CM_SVD_Test = confusion_matrix(YSVD_test,YhatSVD_test);\n",
    "CM_Tree_Test = confusion_matrix(YDT_test,YhatDT_test);\n",
    "\n",
    "print('SVD Train Conf. Matrix: '+'\\n'+str(CM_SVD_Train)+'\\n')\n",
    "print('Tree Train Conf. Matrix: '+'\\n'+str(CM_Tree_Train)+'\\n')\n",
    "\n",
    "print('SVD Test Conf. Matrix: '+'\\n'+str(CM_SVD_Test)+'\\n')\n",
    "print('Tree Test Conf. Matrix: '+'\\n'+str(CM_Tree_Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0771abc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Training Data Set:\n",
      "Total Readmitted Patients: 7700\n",
      "Total Correctly Predicted: 0\n",
      "\n",
      "Tree Training Data Set:\n",
      "Total Readmitted Patients: 7700\n",
      "Total Correctly Predicted: 67\n"
     ]
    }
   ],
   "source": [
    "SVD_train_total = np.sum(CM_SVD_Train,axis=1)[1];\n",
    "SVD_train_correct = CM_SVD_Train[1][1];\n",
    "\n",
    "Tree_train_total = np.sum(CM_Tree_Train,axis=1)[1];\n",
    "Tree_train_correct = CM_Tree_Train[1][1];\n",
    "\n",
    "print('SVD Training Data Set:')\n",
    "print('Total Readmitted Patients: '+str(SVD_train_total))\n",
    "print('Total Correctly Predicted: '+str(SVD_train_correct)+'\\n')\n",
    "print('Tree Training Data Set:')\n",
    "print('Total Readmitted Patients: '+str(Tree_train_total))\n",
    "print('Total Correctly Predicted: '+str(Tree_train_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b5814df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD Test Data Set:\n",
      "Total Readmitted Patients: 3657\n",
      "Total Correctly Predicted: 0\n",
      "\n",
      "Tree Test Data Set:\n",
      "Total Readmitted Patients: 3657\n",
      "Total Correctly Predicted: 27\n"
     ]
    }
   ],
   "source": [
    "SVD_test_total = np.sum(CM_SVD_Test,axis=1)[1];\n",
    "SVD_test_correct = CM_SVD_Test[1][1];\n",
    "\n",
    "Tree_test_total = np.sum(CM_Tree_Test,axis=1)[1];\n",
    "Tree_test_correct = CM_Tree_Test[1][1];\n",
    "\n",
    "print('SVD Test Data Set:')\n",
    "print('Total Readmitted Patients: '+str(SVD_test_total))\n",
    "print('Total Correctly Predicted: '+str(SVD_test_correct)+'\\n')\n",
    "print('Tree Test Data Set:')\n",
    "print('Total Readmitted Patients: '+str(Tree_test_total))\n",
    "print('Total Correctly Predicted: '+str(Tree_test_correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cdf735",
   "metadata": {},
   "source": [
    "From what you say it seems class 0 is 19 times more frequent than class 1. So you should increase the class_weight of class 1 relative to class 0, say {0:.9, 1:.1}.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c7c66620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of correct assignments is:  0.5275361893727175\n"
     ]
    }
   ],
   "source": [
    "SVD_Train_Correct = sum(np.diag(CM_SVD_Train))\n",
    "SVD_Train_Total = len(XSVD_train)\n",
    "\n",
    "print('The percentage of correct assignments is: ',SVD_Train_Correct/SVD_Train_Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3887b560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68183"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(CM_SVD_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "686c12c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68183"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(XSVD_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889cfc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
